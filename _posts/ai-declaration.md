# An AI content declaration standard

`Hu`

Since generative AI models became mainstream, even of bot-origin, there has been a deluge of pure AI and AI assisted 'original' content published.

If distinguishing man's content from Skynet's is valuable, then I believe there is a need for a standard declaration that authors might use to inform readers that these words are - in fact - of organic origin:

* Automated AI content detection (*something ironic about this being automated...*) produces false-positives at worst and is flaky at best. Detecting AI content by inspection of writing style, etc., is a perpetually losing arms-race against a better funded and motivated foe.
* The internet is generative AI's training set. Polluting the internet with its own content *undistinguished* from man's risks deteriorating not just the quality of the internet's content, (which, in fairness, is probably already 99% trash thanks to [article spinning](https://en.wikipedia.org/wiki/Article_spinning)) but also the quality of the models trained upon it.
  * *"Just train it on pre 2021 content"* - No, unwise strawman: Humanity of the 2030s, 2040s, and beyond simply will not tolerate the veracity of such a dated AI. It was annoying enough having ChatGPT 3 be blind to the war in Ukraine; imagine trying to discuss contemporary topics with someone who woke from a coma after 10, 20, or 30 years.
* 